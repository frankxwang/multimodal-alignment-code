{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd3b116-47b7-4d11-ada7-01743e33502d",
   "metadata": {},
   "source": [
    "# Experiments with word order pair swap debiasing for Winoground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1603a-56c8-4c76-94f3-20a6a12dcb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, BlipForImageTextRetrieval, AutoTokenizer, AutoModelForMaskedLM, CLIPModel, CLIPProcessor\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from main.experiment import *\n",
    "from main.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb010d-2782-42f1-9231-f4269ae47e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27037937-bdce-4a5a-9349-ab2b90efca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "winoground = load_dataset(\"facebook/winoground\", use_auth_token=True)[\"test\"]\n",
    "\n",
    "blip_clm_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "blip_clm_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)\n",
    "blip_clm_model.eval()\n",
    "\n",
    "blip_itm_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-itm-large-coco\")\n",
    "blip_itm_model = BlipForImageTextRetrieval.from_pretrained(\"Salesforce/blip-itm-large-coco\").to(device)\n",
    "blip_itm_model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c7a5b-39c9-45a5-bae9-88e6dad43cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "images0 = winoground[\"image_0\"]\n",
    "images1 = winoground[\"image_1\"]\n",
    "captions0 = winoground[\"caption_0\"]\n",
    "captions1 = winoground[\"caption_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13475535-84d5-4cc3-a8da-5ac6806c6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = list(zip(images0, images1, images0, images1))\n",
    "caption_data = list(zip(captions0, captions0, captions1, captions1))\n",
    "\n",
    "image_data_ragged = RaggedList(image_data)\n",
    "caption_data_ragged = RaggedList(caption_data)\n",
    "\n",
    "image_data_flat = image_data_ragged.flatten()\n",
    "caption_data_flat = caption_data_ragged.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd0b6c-e34b-4882-aaf0-dad7613cf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "mlm = AutoModelForMaskedLM.from_pretrained('roberta-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74454c-71e6-404a-824a-f50de2d147be",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_causal_score = CausalLLMTextScorer(mlm, mlm_tokenizer)\n",
    "pair_text_gen = PairSwapsTextGenerator(text_scorer=roberta_causal_score, best_k=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f7968-4845-4462-a318-96bbd7e8c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    alt_caps = pair_text_gen.generate(caption_data_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe95172-27ab-4bbc-a1b5-4c23a9faa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it_scorer = BLIPImageTextScorer(blip_itm_model, blip_itm_processor, clm_ignore_sep=True, score_type=BLIPScoreType.ITM)\n",
    "it_scorer = BLIPImageTextScorer(blip_itm_model, blip_itm_processor, score_type=BLIPScoreType.CONTRASTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f77a4d-a2e9-48a3-8dc6-63adf4d012d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    orig_scores = it_scorer.score(image_data_flat, caption_data_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ecda62-c4d3-491e-bcfe-2d1851e563fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_caps_ragged = RaggedList(alt_caps)\n",
    "alt_caps_flat = alt_caps_ragged.flatten()\n",
    "image_data_flat_flat = alt_caps_ragged.flatten_broadcast(image_data_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc223581-5c04-4eae-927c-72fe91dbc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    new_scores = it_scorer.score(image_data_flat_flat, alt_caps_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d1809-5495-4f9c-b928-0ab063f1572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unflat_orig_scores = caption_data_ragged.unflatten(orig_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfdb99b-a961-49df-bd55-7b873b0973ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_scores = torch.tensor(unflat_orig_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8aedc-2ec2-421d-91d1-03a0dc9ae106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_mean(vec, k=10):\n",
    "    vec = torch.tensor(vec)\n",
    "    return torch.topk(vec, k).values.mean()\n",
    "\n",
    "new_scores_unflat = alt_caps_ragged.unflatten(new_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294128a9-a1ff-4d1d-a1b4-35ad492d4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    avg_new_scores = [torch.tensor(new_scores_row[:i]).mean() for new_scores_row in new_scores_unflat]\n",
    "    avg_new_scores = caption_data_ragged.unflatten(avg_new_scores)\n",
    "    bias_scores = torch.tensor(avg_new_scores)\n",
    "    new_scores = original_scores - bias_scores\n",
    "    print(i, torch.sum((new_scores[..., 0] > new_scores[..., 1]) & (new_scores[..., 3] > new_scores[..., 2])) / len(new_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
